Where I left off:

4/3/25:
Wrote initializer and configrator component for ESP I2C interface for use with gyroscope/accelerometer module.
Need to do a more in-depth reading of the gy/acc datasheet to figure out how to format message send/receive. This should be done in main/main.c using the i2c_master_transmit(), i2c_master_receive, and i2c_master_transmit_receive() functions described here: 

https://docs.espressif.com/projects/esp-idf/en/v5.2.5/esp32/api-reference/peripherals/i2c.html#_CPPv419i2c_master_transmit23i2c_master_dev_handle_tPK7uint8_t6size_ti

Once that is done, I can begin testing, probably by using the logic analyzer and/or connecting the gy521 to the ESP32 and sending/receiving actual messages.

4/9/25:
Added some code to send and receive messages to the gy/acc module. Specifically, the code added to the main method attempts to read from some of the gy/acc registers. The registers it attempts to read from contain the gyroscope and acceloremeter x, y, z readings.

The next step is to set up the hardware and test out the code. If everything works, the raw data read from the registers will be printed to the ESP log. In the more likely event that everything does not work, I can break out a logic analyzer and sniff the messages directly and see where things are behaving differently than expected. 

4/11/25:
I set up the hardware and tested the code. It appears that the accelerometer reading is correct (x = 0g, y = 0g, z = 1g when on a flat surface). The gyroscope reading indicated about 5deg/s x, and 0deg/s y, z. I am not sure if this is to be expected or not.

5/4/25:
After extensive testing using 1D and 2D simulations, I think it is necessary to build some hardware to determine if the simulations are actually going to be useful for PID tuning or whatever other purpose they may prove to be useful for. 

Given this, I am now switching from working on purely software sim/test to a hardware-based test method. First, I am adding bluetooth control to the drone, so that tests can be started, stopped, or otherwise manipulated without physical intervention. 

The bluetooth control will be based on the examples in esp-idf/examples/bluetooth/ble_get_started/nimble/* which is located at:

https://github.com/espressif/esp-idf/tree/master/examples/bluetooth/ble_get_started/nimble/

I would like to be able to control the device from my cellphone, the examples use a cellphone app, so I think this should be possible.

Update 2:
after significant struggle, I was able to make th Beacon example work in my project. The main issue was, I suspect, with the sdkconfig file. I needed to enable bt and enable nimble in that sdkconfig file for everything else to work. 

Originally, I had organized the bluetooth code into a separate component, along with the adc, i2c, and mcpwm code, primarily for consistency and organizational purposes. However, while troubleshooting, I deleted the component and instead organized the bluetooth code into the main component under the "srcs" and "include" directories. However, as I already mentioned, I don't believe that the organization of the code into a component was the reason for the issues I was experiencing. I am busy now, but when I have some time later I plan to recreate the nimble component and move the bluetooth code back into it. 

5/9/2025:
Yesterday, I added the GAP connection and GATT server to the code so that the
board (GATT server) can communicate with another device, such as a cellphone or
computer (GATT client) to transfer data or commands in either direction.

Currently, the code is directly from the ESP IDF examples, so the communication consists
of the GATT client being able to send an ON or OFF command to the LED, 
and the GATT server sendind (either via indication or via client read) randomly
generated heartbeat data.

What I want the comms to consist of is control data (which could be a lot of different
things) from the client to the server, and kinetics data as an indication
from the server to the client. 

The control data should start simple, just turn the motors on (maybe at 1/2 max speed)
or turn them off. The kinetics data should also start simple, initially just one 
piece of the accelerometer or gyroscope data. 

Eventually, I want control to be in the form of 3D direction (move up, down, side to side,
front to back, pitch, roll, yaw)

The goal for the kinetics data is less clear, in general more data is better, but 
the data is mainly to inform design/debugging, so what data is sent will likely depend
on where I am in the design process and what issues need to be debugged. 

5/9/2025 PM update:
I played around with the bluetooth code, and I believe I have the following implemented, although
I won't be able to test it until later today at the earliest:
1. MCPWM control from a bluetooth client, all 4 motors can be turned on at full speed or off
2. On-board LED turns on when BT connected, off when disconnected. 
3. I added a schematic showing the wiring of external components, which currently consists of 
	a. 3.3v LiPo battery
	b. 4 motors, each with flyback diodes and amplifying transistors to allow them to be
		controlled by PWM
	c. The GY-521 accelerometer/gyroscope

The next few things on the list are:
# 1. test the BLE MCPWM control, using a logic analyzer would be easiest/most accurate method
# 2. Test the on-board LED functionality
3. Verify the accuracy of the schematic, also, make a better schematic
4. Replace the heart-rate indication with feedback of sensor data from the drone to the GATT client
5. Add more sensors, probably will use an ultrasonic for z-height detection (although this will
only work at limited pitch/roll angles)
6. Print the drone body 
# 7. Wire up the remaining components --> Done up to current sensor suite, probably need to add more
sensors, currently we only have the accelerometer/gyroscope

------------------------
SENSOR SUITE:
The current sensor suite must estimate 6 state parameters:
x, y, z, pitch, roll, yaw

x, y, and z are to be estimated by double integrating the accelerometer values 
with plans to add an ultrasonic sensor so that z can be estimated using both sensors

pitch and roll are estimated by a combination of the following:
a. integration of the gyroscope values
b. instantaneous measurement by the accelerometer (proportion of z/x or z/y acceleration) 
allows us to determine pitch and roll using trigonometry

yaw is estimated by integration of the gyroscope values


Therefore, x, y, and yaw are estimated using a single sensor each, and 
z, pitch, and roll are each estimated using a combination of two sensors. 

Fortunately, x, y, and yaw are not the most critical parameters for stability, assuming
the drone is not flying in a constricted area. In other words, as long as pitch, roll,
and z are stable, if the drone drifts in the x, y, or yaw DoF, that will probably be ok.

------------------------